epochs: 100
batch_size: ${hardware.memory.batch_size}  # Will be set by machine config
accumulate_grad_batches: 1
num_workers: ${hardware.workers.num_workers}
lr_scheduler:
  name: plateau
  monitor: val_loss
  patience: 5
  factor: 0.1
early_stopping:
  monitor: val_loss
  patience: 10
  mode: min
checkpoint:
  save_top_k: 3
  monitor: val_loss
  mode: min
trainer:
  log_every_n_steps: 10
  check_val_every_n_epoch: 1